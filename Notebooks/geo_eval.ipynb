{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geographical Evaluation using Open Street Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install googlemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polars version: 1.9.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import googlemaps\n",
    "from geopy.distance import geodesic\n",
    "from typing import List, Tuple, Dict, Union\n",
    "from geopy.geocoders import Nominatim\n",
    "from pprint import pprint\n",
    "\n",
    "print(f'polars version: {pl.__version__}')\n",
    "\n",
    "project_dir = Path(os.getcwd()).parent\n",
    "data_dir = project_dir / 'Data'\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"geocoder_llm_project\", timeout=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_parquet(data_dir / 'new_formatted_addresses.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4524, Old Caldwell Mill Road, Shelby County, Alabama, 35242\n",
      "33.41236637208968 -86.73952124099591\n"
     ]
    }
   ],
   "source": [
    "idx = 100\n",
    "print(df[idx]['FormattedFullAddress'].item())\n",
    "print(df[idx]['Latitude'].item(), df[idx]['Longitude'].item())\n",
    "# df[idx].to_dict(as_series=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GeoEvaluation class is designed to evaluate the accuracy of predicted geographic locations by comparing them with ground truth coordinates. It utilizes the OpenStreetMap's `Nominatim` geocoding service to convert textual addresses into geographic coordinates (latitude and longitude) and then calculates the geodesic distance between the predicted and actual locations.\n",
    "\n",
    "A radius threshold of 0.2 kilometers (200 meters) to determine if two locations are considered the same\n",
    "\n",
    "Methods:<br>\n",
    "* `geocode_address(address: str) -> Union[Tuple[float, float], Tuple[None, None]]`<br>\n",
    "This method takes a textual address as input and returns its geographic coordinates.\n",
    "\n",
    "* `compute_geographic_distance(latitude1: float, longitude1: float, latitude2: float, longitude2: float) -> float`<br>\n",
    "This method calculates the geodesic distance between two geographic points.\n",
    "\n",
    "* `are_same(predicted_address: str, groundtruth_latitude: float, groundtruth_longitude: float) -> bool`<br>\n",
    "This method determines whether a predicted address corresponds to the same location as the ground truth coordinates.\n",
    "\n",
    "Process:\n",
    "* * Geocodes the predicted address to obtain its coordinates\n",
    "* * Calculates the distance between the predicted and ground truth coordinates\n",
    "* * Prints the distance for debugging/information purposes\n",
    "* * Returns True if the distance is less than or equal to the radius threshold (0.2 km)\n",
    "\n",
    "Evaluation Logic\n",
    "The class considers two locations to be the same if they are within 200 meters (0.2 kilometers) of each other. This threshold accounts for:\n",
    "\n",
    "Geocoding Imprecision: Different geocoding services might return slightly different coordinates for the same address\n",
    "Address Ambiguity: Addresses can sometimes refer to large buildings or areas rather than precise points\n",
    "Practical Equivalence: For many applications, locations within 200 meters are functionally equivalent\n",
    "\n",
    "The threshold can be adjusted by changing the radius_threshold property depending on the specific requirements of your evaluation task. A smaller threshold would increase precision requirements, while a larger threshold would be more lenient in considering locations as matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoEvaluation:\n",
    "    def __init__(self):\n",
    "        self.timeout = 300\n",
    "        self.geocoder = Nominatim(user_agent=\"geocoder_llm_evaluation_agent\", timeout=self.timeout)\n",
    "        self.radius_threshold = 0.2  # in kilometers\n",
    "\n",
    "    def geocode_address(self, address: str) -> Union[Tuple[float, float], Tuple[None, None]]:\n",
    "        try:\n",
    "            location = self.geocoder.geocode(address)\n",
    "            if location:\n",
    "                return (location.latitude, location.longitude)\n",
    "            print(f\"Did not find location for: {address}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Geocoding error for address '{address}': {e}\")\n",
    "        return (None, None)\n",
    "\n",
    "    def compute_geographic_distance(self, latitude1: float, longitude1: float, latitude2: float, longitude2: float) -> float:\n",
    "        \"\"\"\n",
    "        Compute the geodesic distance between two lat/lon pairs in kilometers using geopy.\n",
    "        \"\"\"\n",
    "        return geodesic((latitude1, longitude1), (latitude2, longitude2)).kilometers\n",
    "\n",
    "    def are_same(self, predicted_address: str, groundtruth_latitude: float, groundtruth_longitude: float) -> bool:\n",
    "        # Geocode predicted address\n",
    "        pred_latitude, pred_longitude = self.geocode_address(predicted_address)\n",
    "        if pred_latitude is None or pred_longitude is None:\n",
    "            return False\n",
    "\n",
    "        # Compute the geographical distance\n",
    "        distance = self.compute_geographic_distance(\n",
    "            float(pred_latitude), float(pred_longitude),\n",
    "            float(groundtruth_latitude), float(groundtruth_longitude)\n",
    "        )\n",
    "\n",
    "        print(f'Distance from ground truth: {round(distance, 3)} KM')\n",
    "\n",
    "        return distance <= self.radius_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance from ground truth: 0.195 KM\n",
      "Match: True\n"
     ]
    }
   ],
   "source": [
    "evaluator = GeoEvaluation()\n",
    "groundtruth_lat, groundtruth_lon = 32.79596540137694, -85.6535596907001\n",
    "predicted_address = \"south main st, Camp Hill, Alabama, 36850\"\n",
    "\n",
    "is_match = evaluator.are_same(predicted_address, groundtruth_lat, groundtruth_lon)\n",
    "print(\"Match:\", is_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_parquet(data_dir / 'address_with_instructions.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 71)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>OID_</th><th>AddNum_Pre</th><th>Add_Number</th><th>AddNum_Suf</th><th>AddNo_Full</th><th>St_PreMod</th><th>St_PreDir</th><th>St_PreTyp</th><th>St_PreSep</th><th>St_Name</th><th>St_PosTyp</th><th>St_PosDir</th><th>St_PosMod</th><th>StNam_Full</th><th>Building</th><th>Floor</th><th>Unit</th><th>Room</th><th>Seat</th><th>Addtl_Loc</th><th>SubAddress</th><th>LandmkName</th><th>County</th><th>Inc_Muni</th><th>Post_City</th><th>Census_Plc</th><th>Uninc_Comm</th><th>Nbrhd_Comm</th><th>NatAmArea</th><th>NatAmSub</th><th>Urbnztn_PR</th><th>PlaceOther</th><th>PlaceNmTyp</th><th>State</th><th>Zip_Code</th><th>Plus_4</th><th>UUID</th><th>AddAuth</th><th>AddrRefSys</th><th>Longitude</th><th>Latitude</th><th>NatGrid</th><th>Elevation</th><th>Placement</th><th>AddrPoint</th><th>Related_ID</th><th>RelateType</th><th>ParcelSrc</th><th>Parcel_ID</th><th>AddrClass</th><th>Lifecycle</th><th>Effective</th><th>Expire</th><th>DateUpdate</th><th>AnomStatus</th><th>LocatnDesc</th><th>Addr_Type</th><th>DeliverTyp</th><th>NAD_Source</th><th>DataSet_ID</th><th>StreetAddress</th><th>SecondaryAddress</th><th>CityStateZip</th><th>FullAddress</th><th>FormattedFullAddress</th><th>task1_instruction</th><th>task1_groundtruth</th><th>task2_instruction</th><th>task2_groundtruth</th><th>noise_level</th><th>variant_idx</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>62241576</td><td>&quot;&quot;</td><td>1187</td><td>&quot;&quot;</td><td>1187</td><td>&quot;&quot;</td><td>&quot;north&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;pownal&quot;</td><td>&quot;road&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;north pownal road&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;bennington&quot;</td><td>&quot;NaN&quot;</td><td>&quot;pownal&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;vt&quot;</td><td>5260</td><td>null</td><td>&quot;{2adfa62f-3b16-475b-96d3-726f7…</td><td>null</td><td>&quot;&quot;</td><td>&quot;-73.2482712649639&quot;</td><td>&quot;42.8039371512875&quot;</td><td>&quot;18txn4323540530&quot;</td><td>&quot;&quot;</td><td>&quot;NaN&quot;</td><td>&quot;-73.2482712649639 42.803937151…</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;numbered thoroughfare address&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;5/27/2016 9:33:29&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;residential&quot;</td><td>&quot;&quot;</td><td>&quot;vermontenhanced911board&quot;</td><td>&quot;134413&quot;</td><td>&quot;1187 north pownal road&quot;</td><td>&quot;&quot;</td><td>&quot;pownal, vt, 5260&quot;</td><td>&quot;1187 north pownal road\n",
       "\n",
       "pownal…</td><td>&quot;1187, north Pownal Road, Benni…</td><td>&quot;Parse the following address in…</td><td>&quot;{\n",
       "  &quot;AddNum_Pre&quot;: &quot;&quot;,\n",
       "  &quot;Add_N…</td><td>&quot;Fix the formatting, structure,…</td><td>&quot;{\n",
       "  &quot;AddNum_Pre&quot;: &quot;&quot;,\n",
       "  &quot;Add_N…</td><td>&quot;medium&quot;</td><td>0</td></tr><tr><td>19781905</td><td>&quot;&quot;</td><td>1124</td><td>&quot;&quot;</td><td>1124</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;judah bear&quot;</td><td>&quot;boulevard&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;judah bear boulevard&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;madison&quot;</td><td>&quot;richmond&quot;</td><td>&quot;richmond&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;ky&quot;</td><td>40475</td><td>null</td><td>&quot;{fbbed738-c83d-41c2-b4ca-bf33c…</td><td>null</td><td>&quot;&quot;</td><td>&quot;-84.25537236725299&quot;</td><td>&quot;37.754618638845024&quot;</td><td>&quot;16sgg4179582137&quot;</td><td>&quot;&quot;</td><td>&quot;NaN&quot;</td><td>&quot;-84.25537236725299 37.75461863…</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;numbered thoroughfare address&quot;</td><td>&quot;&quot;</td><td>&quot;1/31/2024 0:00:00&quot;</td><td>&quot;12/31/2024 0:00:00&quot;</td><td>&quot;11/3/2022 0:00:00&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;stateofkentucky&quot;</td><td>&quot;ssap_94076madisoncountyky.us&quot;</td><td>&quot;1124 judah bear boulevard&quot;</td><td>&quot;&quot;</td><td>&quot;richmond, ky, 40475&quot;</td><td>&quot;1124 judah bear boulevard\n",
       "\n",
       "ric…</td><td>&quot;1124, Judah Bear Boulevard, Ri…</td><td>&quot;Parse the following address in…</td><td>&quot;{\n",
       "  &quot;AddNum_Pre&quot;: &quot;&quot;,\n",
       "  &quot;Add_N…</td><td>&quot;Fix the formatting, structure,…</td><td>&quot;{\n",
       "  &quot;AddNum_Pre&quot;: &quot;&quot;,\n",
       "  &quot;Add_N…</td><td>&quot;extreme&quot;</td><td>2</td></tr><tr><td>21790301</td><td>&quot;&quot;</td><td>27</td><td>&quot;&quot;</td><td>27</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;captain bellamy&quot;</td><td>&quot;lane&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;captain bellamy lane&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;barnstable&quot;</td><td>&quot;barnstable&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;centerville&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;ma&quot;</td><td>2632</td><td>null</td><td>&quot;{8ad0ef9e-2733-7335-7ae0-03faa…</td><td>null</td><td>&quot;uninc_comm&quot;</td><td>&quot;-70.330290313&quot;</td><td>&quot;41.6600585620001&quot;</td><td>&quot;19tcg8924212888&quot;</td><td>&quot;&quot;</td><td>&quot;structure - rooftop&quot;</td><td>&quot;-70.330290313 41.6600585620001&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;numbered thoroughfare address&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;1/20/2014 0:00:00&quot;</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;residential&quot;</td><td>&quot;&quot;</td><td>&quot;massgismassachusetts&quot;</td><td>&quot;43420&quot;</td><td>&quot;27 captain bellamy lane&quot;</td><td>&quot;&quot;</td><td>&quot;ma, 2632&quot;</td><td>&quot;27 captain bellamy lane\n",
       "\n",
       "ma, 2…</td><td>&quot;27, Captain Bellamy Lane, Cent…</td><td>&quot;Parse the following address in…</td><td>&quot;{\n",
       "  &quot;AddNum_Pre&quot;: &quot;&quot;,\n",
       "  &quot;Add_N…</td><td>&quot;Fix the formatting, structure,…</td><td>&quot;{\n",
       "  &quot;AddNum_Pre&quot;: &quot;&quot;,\n",
       "  &quot;Add_N…</td><td>&quot;medium&quot;</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 71)\n",
       "┌──────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ OID_     ┆ AddNum_Pr ┆ Add_Numbe ┆ AddNum_Su ┆ … ┆ task2_ins ┆ task2_gro ┆ noise_lev ┆ variant_i │\n",
       "│ ---      ┆ e         ┆ r         ┆ f         ┆   ┆ truction  ┆ undtruth  ┆ el        ┆ dx        │\n",
       "│ i64      ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│          ┆ str       ┆ i64       ┆ str       ┆   ┆ str       ┆ str       ┆ str       ┆ i64       │\n",
       "╞══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 62241576 ┆           ┆ 1187      ┆           ┆ … ┆ Fix the   ┆ {         ┆ medium    ┆ 0         │\n",
       "│          ┆           ┆           ┆           ┆   ┆ formattin ┆ \"AddNum_P ┆           ┆           │\n",
       "│          ┆           ┆           ┆           ┆   ┆ g, struct ┆ re\": \"\",  ┆           ┆           │\n",
       "│          ┆           ┆           ┆           ┆   ┆ ure,…     ┆   \"Add_N… ┆           ┆           │\n",
       "│ 19781905 ┆           ┆ 1124      ┆           ┆ … ┆ Fix the   ┆ {         ┆ extreme   ┆ 2         │\n",
       "│          ┆           ┆           ┆           ┆   ┆ formattin ┆ \"AddNum_P ┆           ┆           │\n",
       "│          ┆           ┆           ┆           ┆   ┆ g, struct ┆ re\": \"\",  ┆           ┆           │\n",
       "│          ┆           ┆           ┆           ┆   ┆ ure,…     ┆   \"Add_N… ┆           ┆           │\n",
       "│ 21790301 ┆           ┆ 27        ┆           ┆ … ┆ Fix the   ┆ {         ┆ medium    ┆ 0         │\n",
       "│          ┆           ┆           ┆           ┆   ┆ formattin ┆ \"AddNum_P ┆           ┆           │\n",
       "│          ┆           ┆           ┆           ┆   ┆ g, struct ┆ re\": \"\",  ┆           ┆           │\n",
       "│          ┆           ┆           ┆           ┆   ┆ ure,…     ┆   \"Add_N… ┆           ┆           │\n",
       "└──────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Add_Number</th><th>AddNo_Full</th><th>St_PreDir</th><th>St_Name</th><th>St_PosTyp</th><th>County</th><th>Inc_Muni</th><th>Post_City</th><th>State</th><th>Zip_Code</th><th>Latitude</th><th>Longitude</th></tr><tr><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>1187</td><td>1187</td><td>&quot;north&quot;</td><td>&quot;pownal&quot;</td><td>&quot;road&quot;</td><td>&quot;bennington&quot;</td><td>&quot;NaN&quot;</td><td>&quot;pownal&quot;</td><td>&quot;vt&quot;</td><td>5260</td><td>&quot;42.8039371512875&quot;</td><td>&quot;-73.2482712649639&quot;</td></tr><tr><td>1124</td><td>1124</td><td>&quot;&quot;</td><td>&quot;judah bear&quot;</td><td>&quot;boulevard&quot;</td><td>&quot;madison&quot;</td><td>&quot;richmond&quot;</td><td>&quot;richmond&quot;</td><td>&quot;ky&quot;</td><td>40475</td><td>&quot;37.754618638845024&quot;</td><td>&quot;-84.25537236725299&quot;</td></tr><tr><td>27</td><td>27</td><td>&quot;&quot;</td><td>&quot;captain bellamy&quot;</td><td>&quot;lane&quot;</td><td>&quot;barnstable&quot;</td><td>&quot;barnstable&quot;</td><td>&quot;&quot;</td><td>&quot;ma&quot;</td><td>2632</td><td>&quot;41.6600585620001&quot;</td><td>&quot;-70.330290313&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 12)\n",
       "┌────────────┬────────────┬───────────┬────────────┬───┬───────┬──────────┬────────────┬───────────┐\n",
       "│ Add_Number ┆ AddNo_Full ┆ St_PreDir ┆ St_Name    ┆ … ┆ State ┆ Zip_Code ┆ Latitude   ┆ Longitude │\n",
       "│ ---        ┆ ---        ┆ ---       ┆ ---        ┆   ┆ ---   ┆ ---      ┆ ---        ┆ ---       │\n",
       "│ i64        ┆ i64        ┆ str       ┆ str        ┆   ┆ str   ┆ i64      ┆ str        ┆ str       │\n",
       "╞════════════╪════════════╪═══════════╪════════════╪═══╪═══════╪══════════╪════════════╪═══════════╡\n",
       "│ 1187       ┆ 1187       ┆ north     ┆ pownal     ┆ … ┆ vt    ┆ 5260     ┆ 42.8039371 ┆ -73.24827 │\n",
       "│            ┆            ┆           ┆            ┆   ┆       ┆          ┆ 512875     ┆ 12649639  │\n",
       "│ 1124       ┆ 1124       ┆           ┆ judah bear ┆ … ┆ ky    ┆ 40475    ┆ 37.7546186 ┆ -84.25537 │\n",
       "│            ┆            ┆           ┆            ┆   ┆       ┆          ┆ 38845024   ┆ 236725299 │\n",
       "│ 27         ┆ 27         ┆           ┆ captain    ┆ … ┆ ma    ┆ 2632     ┆ 41.6600585 ┆ -70.33029 │\n",
       "│            ┆            ┆           ┆ bellamy    ┆   ┆       ┆          ┆ 620001     ┆ 0313      │\n",
       "└────────────┴────────────┴───────────┴────────────┴───┴───────┴──────────┴────────────┴───────────┘"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(['Add_Number', 'AddNo_Full', 'St_PreDir', 'St_Name', 'St_PosTyp', 'County', 'Inc_Muni', 'Post_City', 'State', 'Zip_Code', 'Latitude', 'Longitude']).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_record(oid: int, data: pl.DataFrame = df) -> Dict:\n",
    "    record = data.filter(\n",
    "        pl.col('OID_') == oid\n",
    "    )[0].select([\n",
    "        'OID_', \n",
    "        'FormattedFullAddress', \n",
    "        'Latitude', \n",
    "        'Longitude',\n",
    "        'noise_level',\n",
    "        'variant_idx'\n",
    "        ]).to_dict(as_series=False)\n",
    "    return {k : v[0] for k, v in record.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State abbreviation to full name mapping\n",
    "STATE_MAP = {\n",
    "    'TX': 'Texas',\n",
    "    'LA': 'Louisiana',\n",
    "    'ME': 'Maine',\n",
    "    'WY': 'Wyoming',\n",
    "    'KY': 'Kentucky',\n",
    "    'MI': 'Michigan',\n",
    "    'WA': 'Washington',\n",
    "    'VT': 'Vermont',\n",
    "    'ND': 'North Dakota',\n",
    "    'TN': 'Tennessee',\n",
    "    'IN': 'Indiana',\n",
    "    'WV': 'West Virginia',\n",
    "    'MN': 'Minnesota',\n",
    "    'RI': 'Rhode Island',\n",
    "    'DE': 'Delaware',\n",
    "    'IL': 'Illinois',\n",
    "    'SD': 'South Dakota',\n",
    "    'AK': 'Alaska',\n",
    "    'MS': 'Mississippi',\n",
    "    'OK': 'Oklahoma',\n",
    "    'PA': 'Pennsylvania',\n",
    "    'WI': 'Wisconsin',\n",
    "    'NY': 'New York',\n",
    "    'KS': 'Kansas',\n",
    "    'NM': 'New Mexico',\n",
    "    'AZ': 'Arizona',\n",
    "    'SC': 'South Carolina',\n",
    "    'FL': 'Florida',\n",
    "    'NC': 'North Carolina',\n",
    "    'MD': 'Maryland',\n",
    "    'UT': 'Utah',\n",
    "    'NE': 'Nebraska',\n",
    "    'NH': 'New Hampshire',\n",
    "    'VA': 'Virginia',\n",
    "    'GA': 'Georgia',\n",
    "    'AL': 'Alabama',\n",
    "    'CA': 'California',\n",
    "    'MA': 'Massachusetts',\n",
    "    'CT': 'Connecticut',\n",
    "    'AR': 'Arkansas',\n",
    "    'CO': 'Colorado',\n",
    "    'MT': 'Montana',\n",
    "    'DC': 'District of Columbia',\n",
    "    'ID': 'Idaho',\n",
    "    'IA': 'Iowa',\n",
    "    'OH': 'Ohio',\n",
    "    'MO': 'Missouri'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_usdot_to_freeform_granular(data: dict, state_map: dict) -> str:\n",
    "    # Custom null-like values to filter\n",
    "    NULL_STRINGS = {\"\", None, \"nan\", \"null\"}\n",
    "\n",
    "    def safe_get(key):\n",
    "        val = data.get(key)\n",
    "        if isinstance(val, str):\n",
    "            val = val.lower()\n",
    "        return None if (val in NULL_STRINGS or str(val).strip() in NULL_STRINGS) else str(val).strip()\n",
    "\n",
    "    def safe_title(key):\n",
    "        val = safe_get(key)\n",
    "        return val.title() if val else None\n",
    "\n",
    "    # House number\n",
    "    number = \" \".join(filter(None, [safe_get(\"AddNum_Pre\"),\n",
    "                                    safe_get(\"Add_Number\"),\n",
    "                                    safe_get(\"AddNum_Suf\")]))\n",
    "\n",
    "    # Street full\n",
    "    street_parts = [\n",
    "        safe_get(\"St_PreDir\"),\n",
    "        safe_title(\"St_Name\"),\n",
    "        safe_title(\"St_PosTyp\"),\n",
    "        safe_get(\"St_PosDir\")\n",
    "    ]\n",
    "    street = \" \".join(part for part in street_parts if part)\n",
    "\n",
    "    # Unit/building details\n",
    "    sub_parts = []\n",
    "    if safe_get(\"Building\"): sub_parts.append(f\"Bldg {safe_get('Building')}\")\n",
    "    if safe_get(\"Floor\"): sub_parts.append(f\"Floor {safe_get('Floor')}\")\n",
    "    if safe_get(\"Unit\"): sub_parts.append(f\"Unit {safe_get('Unit')}\")\n",
    "    if safe_get(\"Room\"): sub_parts.append(f\"Room {safe_get('Room')}\")\n",
    "\n",
    "    sub_address = \", \".join(sub_parts)\n",
    "\n",
    "    # Town/City\n",
    "    town = safe_title(\"Uninc_Comm\") or safe_title(\"Inc_Muni\")\n",
    "\n",
    "    # County\n",
    "    county = safe_title(\"County\")\n",
    "\n",
    "    # State\n",
    "    state_abbr = safe_get(\"State\")\n",
    "    state_full = state_map.get(state_abbr.upper(), state_abbr) if state_abbr else None\n",
    "\n",
    "    # ZIP\n",
    "    zip_raw = safe_get(\"Zip_Code\")\n",
    "    zip_code = zip_raw.zfill(5) if zip_raw and zip_raw.isdigit() else None\n",
    "\n",
    "    # Compose full address\n",
    "    components = [number, street]\n",
    "    if sub_address:\n",
    "        components.append(sub_address)\n",
    "    components.extend([\n",
    "        town,\n",
    "        f\"{county} County\" if county else None,\n",
    "        state_full,\n",
    "        zip_code\n",
    "    ])\n",
    "\n",
    "    return \", \".join([c for c in components if c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OID_': 23562552,\n",
       " 'FormattedFullAddress': '1, Taunton Street, Somerville, Middlesex County, Massachusetts, 02143',\n",
       " 'Latitude': '42.3769386750001',\n",
       " 'Longitude': '-71.100590605',\n",
       " 'noise_level': 'low',\n",
       " 'variant_idx': 1}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_record(oid=23562552)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 Inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_inf_df = pl.read_csv(data_dir / 'task1_inference_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_address_json(model_output: str, gt: bool = False) -> Dict:\n",
    "    if not gt:\n",
    "        prefix = \"System: \"\n",
    "        json_str = model_output[len(prefix):].strip()\n",
    "    else:\n",
    "        json_str = model_output\n",
    "    address_json = json.loads(json_str)\n",
    "    return address_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_idx = 2\n",
    "record = t1_inf_df[record_idx]\n",
    "\n",
    "t1_groundtruth = record['ground_truth'].item()\n",
    "t1_model_output = record['model_output'].item()\n",
    "\n",
    "grounttruth = parse_address_json(t1_groundtruth, gt=True)\n",
    "modeloutput = parse_address_json(t1_model_output, gt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Entities: {'AddNum_Pre': '', 'Add_Number': '86', 'AddNum_Suf': '', 'St_PreDir': '', 'St_Name': 'p', 'St_PosTyp': 'street', 'St_PosDir': '', 'Building': '', 'Floor': '', 'Unit': '2', 'Room': '', 'Uninc_Comm': 'south boston', 'Inc_Muni': 'boston', 'County': 'suffolk', 'State': 'ma', 'Zip_Code': '2127'}\n",
      "Generated Entities: {'AddNum_Pre': '', 'Add_Number': '86', 'AddNum_Suf': '', 'St_PreDir': '', 'St_Name': 'p', 'St_PosTyp': 'street', 'St_PosDir': '', 'Building': '', 'Floor': '', 'Unit': '2', 'Room': '', 'Uninc_Comm': 'south boston', 'Inc_Muni': 'boston', 'County': 'suffolk', 'State': 'ma', 'Zip_Code': '2127'}\n"
     ]
    }
   ],
   "source": [
    "print(f'GT Entities: {grounttruth}')\n",
    "print(f'Generated Entities: {modeloutput}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_address_parsing(gt: Dict[str, str], pred: Dict[str, str]) -> Dict[str, float]:\n",
    "    assert gt.keys() == pred.keys(), \"Mismatched keys between ground truth and prediction\"\n",
    "\n",
    "    total_fields = len(gt)\n",
    "    correct_fields = 0\n",
    "\n",
    "    total_gt_entities = 0\n",
    "    total_pred_entities = 0\n",
    "    correct_predicted_entities = 0\n",
    "\n",
    "    total_noisy_fields = 0\n",
    "    correctly_corrected_fields = 0\n",
    "\n",
    "    for key in gt:\n",
    "        gt_val = (gt[key] or \"\").strip().lower()\n",
    "        pred_val = (pred[key] or \"\").strip().lower()\n",
    "\n",
    "        # Field-level accuracy\n",
    "        if gt_val == pred_val:\n",
    "            correct_fields += 1\n",
    "\n",
    "        # Precision/Recall entity presence\n",
    "        if gt_val:\n",
    "            total_gt_entities += 1\n",
    "        if pred_val:\n",
    "            total_pred_entities += 1\n",
    "        if gt_val and pred_val and gt_val == pred_val:\n",
    "            correct_predicted_entities += 1\n",
    "\n",
    "        # Correction accuracy (only evaluate on noisy fields)\n",
    "        if gt_val != pred_val and gt_val and (gt_val != (gt[key] or \"\").strip().lower()):\n",
    "            total_noisy_fields += 1\n",
    "            if pred_val == gt_val:\n",
    "                correctly_corrected_fields += 1\n",
    "        elif gt_val != (gt[key] or \"\").strip().lower():  # noisy field\n",
    "            total_noisy_fields += 1\n",
    "            if pred_val == gt_val:\n",
    "                correctly_corrected_fields += 1\n",
    "\n",
    "    # Final metrics\n",
    "    precision = correct_predicted_entities / total_pred_entities if total_pred_entities > 0 else 0.0\n",
    "    recall = correct_predicted_entities / total_gt_entities if total_gt_entities > 0 else 0.0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    field_accuracy = correct_fields / total_fields\n",
    "    correction_accuracy = correctly_corrected_fields / total_noisy_fields if total_noisy_fields > 0 else 1.0\n",
    "\n",
    "    return {\n",
    "        \"field_accuracy\": field_accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"correction_accuracy\": correction_accuracy,\n",
    "        \"num_noisy_fields\": total_noisy_fields,\n",
    "        \"num_correctly_corrected\": correctly_corrected_fields\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_t1_dataset(file_path: str):\n",
    "    df = pl.read_csv(file_path)\n",
    "    acc_list, p_list, r_list, f1_list = [], [], [], []\n",
    "\n",
    "    for row in df.rows(named=True):\n",
    "        try:\n",
    "            gt = parse_address_json(row['ground_truth'], gt=True)\n",
    "            pred = parse_address_json(row['model_output'], gt=False)\n",
    "            \n",
    "            metrics = evaluate_address_parsing(gt, pred)\n",
    "            \n",
    "            acc_list.append(metrics['correction_accuracy'])\n",
    "            p_list.append(metrics['precision'])\n",
    "            r_list.append(metrics['recall'])\n",
    "            f1_list.append(metrics['f1_score'])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return {\n",
    "        \"avg_field_accuracy\": sum(acc_list) / len(acc_list),\n",
    "        \"avg_precision\": sum(p_list) / len(p_list),\n",
    "        \"avg_recall\": sum(r_list) / len(r_list),\n",
    "        \"avg_f1_score\": sum(f1_list) / len(f1_list)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg_field_accuracy': 1.0, 'avg_precision': 1.0, 'avg_recall': 1.0, 'avg_f1_score': 1.0}\n"
     ]
    }
   ],
   "source": [
    "summary = evaluate_t1_dataset(data_dir / 'task1_inference_results.csv')\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt: {'AddNum_Pre': '', 'Add_Number': '201', 'AddNum_Suf': '', 'St_PreDir': '', 'St_Name': 'sanders', 'St_PosTyp': 'street', 'St_PosDir': '', 'Building': '', 'Floor': '', 'Unit': '1', 'Room': '', 'Uninc_Comm': 'athol', 'Inc_Muni': 'athol', 'County': 'worcester', 'State': 'ma', 'Zip_Code': '1331'}\n",
      "pred: {'AddNum_Pre': '', 'Add_Number': '201', 'AddNum_Suf': '', 'St_PreDir': '', 'St_Name': 'sanders', 'St_PosTyp': 'street', 'St_PosDir': '', 'Building': '', 'Floor': '', 'Unit': '1', 'Room': '', 'Uninc_Comm': 'athol', 'Inc_Muni': 'athol', 'County': 'worcester', 'State': 'ma', 'Zip_Code': '1331'}\n",
      "{'OID_': 25146114, 'FormattedFullAddress': '201, Sanders Street, Unit 1, Athol, Worcester County, Massachusetts, 01331', 'Latitude': '42.588018678', 'Longitude': '-72.231960989', 'noise_level': 'high', 'variant_idx': 1}\n"
     ]
    }
   ],
   "source": [
    "record = t1_inf_df[50]\n",
    "\n",
    "gt = parse_address_json(record['ground_truth'].item(), gt=True)\n",
    "pred = parse_address_json(record['model_output'].item(), gt=False)\n",
    "\n",
    "metadata = get_record(oid=record['OID_'].item())\n",
    "\n",
    "prompt = record['instruction'].item()\n",
    "\n",
    "print(f'gt: {gt}')\n",
    "print(f'pred: {pred}')\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse the following address into a structured JSON with these fields: AddNum_Pre, Add_Number, AddNum_Suf, St_PreDir, St_Name, St_PosTyp, St_PosDir, Building, Floor, Unit, Room, Uninc_Comm, Inc_Muni, County, State, Zip_Code.\n",
      "Address: 201, Sanders Street, Unit 1, Athol, Worcester County, Massachusetts, 01331\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 Inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of task 2 inferences: 100\n"
     ]
    }
   ],
   "source": [
    "t2_inf_df = pl.read_csv(data_dir / 'task2_inference_results.csv')\n",
    "print(f'Number of task 2 inferences: {len(t2_inf_df)}')\n",
    "\n",
    "secrets_dir = project_dir / 'Secrets'\n",
    "\n",
    "with open (secrets_dir / 'gmaps.txt') as f:\n",
    "    gmaps_api = f.read()\n",
    "\n",
    "gmaps_client = googlemaps.Client(key=gmaps_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_address_json_from_prompt(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts the JSON address block from the prompt.\n",
    "    Args:\n",
    "        prompt: The input string containing a prompt and an address JSON.\n",
    "    Returns:\n",
    "        The JSON string portion from the prompt.\n",
    "    \"\"\"\n",
    "    match = re.search(r'(\\{\\s*\".*?\\})$', prompt, re.DOTALL)\n",
    "    return match.group(1) if match else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>OID_</th><th>instruction</th><th>ground_truth</th><th>model_output</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>23562552</td><td>&quot;Fix the formatting, structure,…</td><td>&quot;{\n",
       "  &quot;AddNum_Pre&quot;: &quot;&quot;,\n",
       "  &quot;Add_N…</td><td>&quot;System: {\n",
       "  &quot;AddNum_Pre&quot;: &quot;&quot;,\n",
       "…</td></tr><tr><td>25210416</td><td>&quot;Fix the formatting, structure,…</td><td>&quot;{\n",
       "  &quot;AddNum_Pre&quot;: &quot;&quot;,\n",
       "  &quot;Add_N…</td><td>&quot;System: {\n",
       "  &quot;AddNum_Pre&quot;: &quot;&quot;,\n",
       "…</td></tr><tr><td>24579587</td><td>&quot;Fix the formatting, structure,…</td><td>&quot;{\n",
       "  &quot;AddNum_Pre&quot;: &quot;&quot;,\n",
       "  &quot;Add_N…</td><td>&quot;System: {\n",
       "  &quot;AddNum_Pre&quot;: &quot;&quot;,\n",
       "…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 4)\n",
       "┌──────────┬─────────────────────────────────┬─────────────────────┬─────────────────────┐\n",
       "│ OID_     ┆ instruction                     ┆ ground_truth        ┆ model_output        │\n",
       "│ ---      ┆ ---                             ┆ ---                 ┆ ---                 │\n",
       "│ i64      ┆ str                             ┆ str                 ┆ str                 │\n",
       "╞══════════╪═════════════════════════════════╪═════════════════════╪═════════════════════╡\n",
       "│ 23562552 ┆ Fix the formatting, structure,… ┆ {                   ┆ System: {           │\n",
       "│          ┆                                 ┆   \"AddNum_Pre\": \"\", ┆   \"AddNum_Pre\": \"\", │\n",
       "│          ┆                                 ┆   \"Add_N…           ┆ …                   │\n",
       "│ 25210416 ┆ Fix the formatting, structure,… ┆ {                   ┆ System: {           │\n",
       "│          ┆                                 ┆   \"AddNum_Pre\": \"\", ┆   \"AddNum_Pre\": \"\", │\n",
       "│          ┆                                 ┆   \"Add_N…           ┆ …                   │\n",
       "│ 24579587 ┆ Fix the formatting, structure,… ┆ {                   ┆ System: {           │\n",
       "│          ┆                                 ┆   \"AddNum_Pre\": \"\", ┆   \"AddNum_Pre\": \"\", │\n",
       "│          ┆                                 ┆   \"Add_N…           ┆ …                   │\n",
       "└──────────┴─────────────────────────────────┴─────────────────────┴─────────────────────┘"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2_inf_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Schema([('OID_', Int64),\n",
       "        ('instruction', String),\n",
       "        ('ground_truth', String),\n",
       "        ('model_output', String)])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2_inf_df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_t2_df(data: pl.DataFrame, gmaps_client: str) -> pl.DataFrame:\n",
    "    \n",
    "    enriched_rows = []\n",
    "\n",
    "    for record in data.rows(named=True):\n",
    "        t2_groundtruth = record['ground_truth']\n",
    "        t2_model_output = record['model_output']\n",
    "        prompt = record['instruction']\n",
    "\n",
    "        noisy_json = extract_address_json_from_prompt(prompt)\n",
    "        noisy_json = parse_address_json(noisy_json, gt=True)\n",
    "        grounttruth_json = parse_address_json(t2_groundtruth, gt=True)\n",
    "        modeloutput_json = parse_address_json(t2_model_output, gt=False)\n",
    "\n",
    "        noisy_address = format_usdot_to_freeform_granular(noisy_json, STATE_MAP)\n",
    "        generated_address = format_usdot_to_freeform_granular(modeloutput_json, STATE_MAP)\n",
    "\n",
    "        metadata = get_record(record['OID_'])\n",
    "\n",
    "        predicted_geocoded = gmaps_client.geocode(generated_address)\n",
    "        predicted_geocoded = predicted_geocoded[0][\"geometry\"][\"location\"]\n",
    "\n",
    "        enriched_row = {\n",
    "            \"OID_\": record['OID_'],\n",
    "            \"noise_level\": metadata['noise_level'],\n",
    "            \"variant_idx\": metadata['variant_idx'],\n",
    "            \"noisy_json\": json.dumps(noisy_json),\n",
    "            \"ground_truth_json\": json.dumps(grounttruth_json),\n",
    "            \"predicted_json\": json.dumps(modeloutput_json),\n",
    "            \"groundtruth_address\": metadata['FormattedFullAddress'],\n",
    "            \"groundtruth_latitude\": metadata['Latitude'],\n",
    "            \"groundtruth_longitude\": metadata['Longitude'],\n",
    "            \"noisy_address\": noisy_address,\n",
    "            \"predicted_address\": generated_address,\n",
    "            \"predicted_latitude\": predicted_geocoded['lat'],\n",
    "            \"predicted_longitude\": predicted_geocoded['lng'],\n",
    "            }\n",
    "        enriched_rows.append(enriched_row)\n",
    "\n",
    "    return pl.DataFrame(enriched_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not run this again! Will cost Google Maps API\n",
    "# enriched_t2_df = enrich_t2_df(t2_inf_df, gmaps_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geocode_similarity(lat1: float, lon1: float, lat2: float, lon2: float, radius_threshold_km = 0.2):\n",
    "    delta_distance_km = geodesic((lat1, lon1), (lat2, lon2)).kilometers\n",
    "    return 1 if delta_distance_km <= radius_threshold_km else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_json_corrections(noisy_json: Dict, ground_truth: Dict, generated: Dict) -> Dict:\n",
    "    assert noisy_json.keys() == ground_truth.keys() == generated.keys()\n",
    "\n",
    "    total_noisy_fields = 0\n",
    "    corrected_fields = 0\n",
    "    fieldwise_results = []\n",
    "\n",
    "    for field in noisy_json:\n",
    "        noisy_val = (noisy_json[field] or \"\").strip().lower()\n",
    "        gt_val = (ground_truth[field] or \"\").strip().lower()\n",
    "        pred_val = (generated[field] or \"\").strip().lower()\n",
    "\n",
    "        # Skip if ground truth is empty — can't validate\n",
    "        if not gt_val:\n",
    "            continue\n",
    "\n",
    "        # Consider field noisy if it mismatches GT\n",
    "        if noisy_val != gt_val:\n",
    "            total_noisy_fields += 1\n",
    "            corrected_fields += int(pred_val == gt_val)\n",
    "            fieldwise_results.append({\n",
    "                \"field\": field,\n",
    "                \"noisy\": noisy_val,\n",
    "                \"predicted\": pred_val,\n",
    "                \"ground_truth\": gt_val,\n",
    "                \"is_correct\": pred_val == gt_val\n",
    "            })\n",
    "\n",
    "    accuracy = corrected_fields / total_noisy_fields if total_noisy_fields > 0 else 1.0\n",
    "\n",
    "    return {\n",
    "        \"noisy_fields_total\": total_noisy_fields,\n",
    "        \"corrected_correctly\": corrected_fields,\n",
    "        \"correction_accuracy\": accuracy,\n",
    "        \"fieldwise_analysis\": fieldwise_results\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_geosim_and_json_corrections(df: pl.DataFrame) -> Dict:\n",
    "    total_records = len(df)\n",
    "    geo_similar_count = 0\n",
    "    correction_scores = []\n",
    "\n",
    "    for row in df.iter_rows(named=True):\n",
    "        try:\n",
    "            # Geosimilarity\n",
    "            lat1 = float(row['groundtruth_latitude'])\n",
    "            lon1 = float(row['groundtruth_longitude'])\n",
    "            lat2 = float(row['predicted_latitude'])\n",
    "            lon2 = float(row['predicted_longitude'])\n",
    "\n",
    "            geo_similar = geocode_similarity(lat1, lon1, lat2, lon2)\n",
    "            geo_similar_count += geo_similar\n",
    "\n",
    "            # JSON correction\n",
    "            noisy_json = json.loads(row['noisy_json'])\n",
    "            gt_json = json.loads(row['ground_truth_json'])\n",
    "            pred_json = json.loads(row['predicted_json'])\n",
    "\n",
    "            result = evaluate_json_corrections(noisy_json, gt_json, pred_json)\n",
    "            correction_scores.append(result['correction_accuracy'])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping record {row['OID_']} due to error: {e}\")\n",
    "            continue\n",
    "\n",
    "    avg_correction_accuracy = sum(correction_scores) / len(correction_scores) if correction_scores else 0.0\n",
    "\n",
    "    return {\n",
    "        \"geo_similar_count\": geo_similar_count,\n",
    "        \"total_records\": total_records,\n",
    "        \"geo_similarity_rate\": geo_similar_count / total_records,\n",
    "        \"avg_correction_accuracy\": avg_correction_accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'geo_similar_count': 30,\n",
       " 'total_records': 100,\n",
       " 'geo_similarity_rate': 0.3,\n",
       " 'avg_correction_accuracy': 0.5717103174603173}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_geosim_and_json_corrections(enriched_t2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GeoEvaluation:\n",
    "#     def __init__(self, google_api_key: str = None):\n",
    "#         self.radius_threshold = 0.2\n",
    "#         self.gmaps = googlemaps.Client(key=google_api_key) if google_api_key else None\n",
    "\n",
    "#     def geocode_address(self, address: str) -> Union[Tuple[float, float], Tuple[None, None]]:\n",
    "#         try:\n",
    "#             if self.gmaps:\n",
    "#                 geocode_result = self.gmaps.geocode(address)\n",
    "#                 if geocode_result:\n",
    "#                     loc = geocode_result[0]['geometry']['location']\n",
    "#                     return (loc['lat'], loc['lng'])\n",
    "#             else:\n",
    "#                 print(\"Google Maps client not initialized.\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Google API error for address '{address}': {e}\")\n",
    "#         return (None, None)\n",
    "\n",
    "#     def compute_geographic_distance(self, lat1: float, lon1: float, lat2: float, lon2: float) -> float:\n",
    "#         return geodesic((lat1, lon1), (lat2, lon2)).kilometers\n",
    "\n",
    "#     def are_same(self, predicted_address: str, groundtruth_lat: float, groundtruth_lon: float) -> bool:\n",
    "#         pred_lat, pred_lon = self.geocode_address(predicted_address)\n",
    "#         if pred_lat is None or pred_lon is None:\n",
    "#             return False\n",
    "#         distance = self.compute_geographic_distance(pred_lat, pred_lon, groundtruth_lat, groundtruth_lon)\n",
    "#         print(f\"Distance from ground truth: {round(distance, 3)} KM\")\n",
    "#         return distance <= self.radius_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'noisy_fields_total': 4,\n",
       " 'corrected_correctly': 2,\n",
       " 'correction_accuracy': 0.5,\n",
       " 'fieldwise_analysis': [{'field': 'Add_Number',\n",
       "   'noisy': '74',\n",
       "   'predicted': '47',\n",
       "   'ground_truth': '47',\n",
       "   'is_correct': True},\n",
       "  {'field': 'St_Name',\n",
       "   'noisy': 'ba9 vi4ew',\n",
       "   'predicted': 'beach',\n",
       "   'ground_truth': 'bay view',\n",
       "   'is_correct': False},\n",
       "  {'field': 'County',\n",
       "   'noisy': '',\n",
       "   'predicted': 'essex',\n",
       "   'ground_truth': 'essex',\n",
       "   'is_correct': True},\n",
       "  {'field': 'Zip_Code',\n",
       "   'noisy': '19',\n",
       "   'predicted': '1905',\n",
       "   'ground_truth': '1902',\n",
       "   'is_correct': False}]}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_json_corrections(noisy_json, grounttruth_json, modeloutput_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bay View Avenue, Unit 14, 2Y6N, Essex County, Massachusetts\n",
      "\n",
      "471, Bay View P8En8Me, Unit 1, Essex County\n",
      "\n",
      "74, Ba9 Vi4Ew Avenue, Unit 1, Lynn, Massachusetts, 00019\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = df.filter(\n",
    "    pl.col('OID_') == 21913155\n",
    ")\n",
    "\n",
    "for row in x.rows(named=True):\n",
    "    p = row['task2_instruction']\n",
    "    noisy_add_json = extract_address_json_from_prompt(p)\n",
    "    noisy_add_json = parse_address_json(noisy_add_json, gt=True)\n",
    "    noisy_add = format_usdot_to_freeform_granular(noisy_add_json, STATE_MAP)\n",
    "    print(f'{noisy_add}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

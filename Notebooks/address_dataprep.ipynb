{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.12\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install polars==1.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polars version: 1.9.0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import string\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "print(f'polars version: {pl.__version__}')\n",
    "\n",
    "project_dir = Path(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://nationaladdressdata.s3.amazonaws.com/NAD_r18_TXT.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip_data_file_path = project_dir / 'NAD_r18_TXT.zip'\n",
    "\n",
    "# with zipfile.ZipFile(zip_data_file_path, 'r') as zip_ref:\n",
    "#     zip_ref.extractall(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_file_path = project_dir / 'TXT/NAD_r18.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polars                        1.26.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_overrides = {\n",
    "    \"OID_\": pl.Int64,\n",
    "    \"AddNum_Pre\": pl.Utf8,\n",
    "    \"Add_Number\": pl.Int64,\n",
    "    \"AddNum_Suf\": pl.Utf8,\n",
    "    \"AddNo_Full\": pl.Int64,\n",
    "    \"St_PreMod\": pl.Utf8,\n",
    "    \"St_PreDir\": pl.Utf8,\n",
    "    \"St_PreTyp\": pl.Utf8,\n",
    "    \"St_PreSep\": pl.Utf8,\n",
    "    \"St_Name\": pl.Utf8,\n",
    "    \"St_PosTyp\": pl.Utf8,\n",
    "    \"St_PosDir\": pl.Utf8,\n",
    "    \"St_PosMod\": pl.Utf8,\n",
    "    \"StNam_Full\": pl.Utf8,\n",
    "    \"Building\": pl.Utf8,\n",
    "    \"Floor\": pl.Utf8,\n",
    "    \"Unit\": pl.Utf8,\n",
    "    \"Room\": pl.Utf8,\n",
    "    \"Seat\": pl.Utf8,\n",
    "    \"Addtl_Loc\": pl.Utf8,\n",
    "    \"SubAddress\": pl.Utf8,\n",
    "    \"LandmkName\": pl.Utf8,\n",
    "    \"County\": pl.Utf8,\n",
    "    \"Inc_Muni\": pl.Utf8,\n",
    "    \"Post_City\": pl.Utf8,\n",
    "    \"Census_Plc\": pl.Utf8,\n",
    "    \"Uninc_Comm\": pl.Utf8,\n",
    "    \"Nbrhd_Comm\": pl.Utf8,\n",
    "    \"NatAmArea\": pl.Utf8,\n",
    "    \"NatAmSub\": pl.Utf8,\n",
    "    \"Urbnztn_PR\": pl.Utf8,\n",
    "    \"PlaceOther\": pl.Utf8,\n",
    "    \"PlaceNmTyp\": pl.Utf8,\n",
    "    \"State\": pl.Utf8,\n",
    "    \"Zip_Code\": pl.Int64,\n",
    "    \"Plus_4\": pl.Int64,\n",
    "    \"UUID\": pl.Utf8,\n",
    "    \"AddAuth\": pl.Int64,\n",
    "    \"AddrRefSys\": pl.Utf8,\n",
    "    \"Longitude\": pl.Float64,\n",
    "    \"Latitude\": pl.Float64,\n",
    "    \"NatGrid\": pl.Utf8,\n",
    "    \"Elevation\": pl.Utf8,\n",
    "    \"Placement\": pl.Utf8,\n",
    "    \"AddrPoint\": pl.Utf8,\n",
    "    \"Related_ID\": pl.Utf8,\n",
    "    \"RelateType\": pl.Utf8,\n",
    "    \"ParcelSrc\": pl.Utf8,\n",
    "    \"Parcel_ID\": pl.Utf8,\n",
    "    \"AddrClass\": pl.Utf8,\n",
    "    \"Lifecycle\": pl.Utf8,\n",
    "    \"Effective\": pl.Utf8,\n",
    "    \"Expire\": pl.Utf8,\n",
    "    \"DateUpdate\": pl.Utf8,\n",
    "    \"AnomStatus\": pl.Utf8,\n",
    "    \"LocatnDesc\": pl.Utf8,\n",
    "    \"Addr_Type\": pl.Utf8,\n",
    "    \"DeliverTyp\": pl.Utf8,\n",
    "    \"NAD_Source\": pl.Utf8,\n",
    "    \"DataSet_ID\": pl.Utf8,\n",
    "    \"StreetAddress\": pl.Utf8,\n",
    "    \"SecondaryAddress\": pl.Utf8,\n",
    "    \"CityStateZip\": pl.Utf8,\n",
    "    \"FullAddress\": pl.Utf8,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv(\n",
    "    raw_file_path, \n",
    "    ignore_errors=True, \n",
    "    separator=\",\", \n",
    "    infer_schema_length=0, \n",
    "    quote_char=None, \n",
    "    schema_overrides=schema_overrides,\n",
    "    truncate_ragged_lines=True,\n",
    "    null_values=[\"Not stated\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(pl.col('State').is_not_null())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_states = [\n",
    "    'TX', 'LA', 'ME', 'WY', 'KY', 'MI', 'WA', 'VT', 'ND', 'TN',\n",
    "    'IN', 'WV', 'MN', 'RI', 'DE', 'IL', 'SD', 'AK', 'MS', 'OK',\n",
    "    'PA', 'WI', 'NY', 'KS', 'NM', 'AZ', 'SC', 'FL', 'NC', 'MD',\n",
    "    'UT', 'NE', 'NH', 'VA', 'GA', 'AL', 'CA', 'MA', 'CT', 'AR',\n",
    "    'CO', 'MT', 'DC', 'ID', 'IA', 'OH', 'MO'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(\n",
    "    pl.col('State').is_in(valid_states)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 80044721\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of records: {len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.with_columns(\n",
    "    pl.concat_str(\n",
    "        [\n",
    "            pl.col(\"AddNum_Pre\"),\n",
    "            pl.col(\"Add_Number\").cast(str),\n",
    "            pl.col(\"AddNum_Suf\"),\n",
    "            pl.col(\"St_PreMod\"),\n",
    "            pl.col(\"St_PreDir\"),\n",
    "            pl.col(\"St_PreTyp\"),\n",
    "            pl.col(\"St_Name\"),\n",
    "            pl.col(\"St_PosTyp\"),\n",
    "            pl.col(\"St_PosDir\"),\n",
    "            pl.col(\"St_PosMod\")\n",
    "        ],\n",
    "        separator=\" \",\n",
    "        ignore_nulls=True\n",
    "    ).alias(\"StreetAddress\"),\n",
    "    pl.concat_str(\n",
    "        [\n",
    "            pl.col(\"Building\"),\n",
    "            pl.col(\"Floor\"),\n",
    "            pl.col(\"Unit\"),\n",
    "            pl.col(\"Room\"),\n",
    "            pl.col(\"Seat\"),\n",
    "            pl.col(\"Addtl_Loc\"),\n",
    "            pl.col(\"SubAddress\")\n",
    "        ],\n",
    "        separator=\", \",\n",
    "        ignore_nulls=True\n",
    "    ).alias(\"SecondaryAddress\"),\n",
    "    pl.concat_str(\n",
    "        [\n",
    "            pl.col(\"Post_City\"),\n",
    "            pl.col(\"State\"),\n",
    "            pl.concat_str(\n",
    "                [pl.col(\"Zip_Code\").cast(str), pl.col(\"Plus_4\").cast(str)],\n",
    "                separator=\"-\",\n",
    "                ignore_nulls=True\n",
    "            )\n",
    "        ],\n",
    "        separator=\", \",\n",
    "        ignore_nulls=True\n",
    "    ).alias(\"CityStateZip\")\n",
    ")\n",
    "\n",
    "df = df.with_columns(\n",
    "    pl.concat_str(\n",
    "        [\n",
    "            pl.col(\"StreetAddress\"),\n",
    "            pl.col(\"SecondaryAddress\"),\n",
    "            pl.col(\"CityStateZip\")\n",
    "        ],\n",
    "        separator=\"\\n\",\n",
    "        ignore_nulls=True\n",
    "    ).alias(\"FullAddress\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Address Length: 42.41529813065374 | Median Address Length: 41.0\n"
     ]
    }
   ],
   "source": [
    "mean_add_len = df.with_columns(pl.col('FullAddress').str.len_chars().alias('AddressLength'))['AddressLength'].mean()\n",
    "median_add_len = df.with_columns(pl.col('FullAddress').str.len_chars().alias('AddressLength'))['AddressLength'].median()\n",
    "\n",
    "print(f'Mean Address Length: {mean_add_len} | Median Address Length: {median_add_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_name_abbr_tuples = [\n",
    "    (\"Alabama\", \"AL\"),\n",
    "    (\"Alaska\", \"AK\"),\n",
    "    (\"Arizona\", \"AZ\"),\n",
    "    (\"Arkansas\", \"AR\"),\n",
    "    (\"California\", \"CA\"),\n",
    "    (\"Colorado\", \"CO\"),\n",
    "    (\"Connecticut\", \"CT\"),\n",
    "    (\"Delaware\", \"DE\"),\n",
    "    (\"District of Columbia\", \"DC\"),\n",
    "    (\"Florida\", \"FL\"),\n",
    "    (\"Georgia\", \"GA\"),\n",
    "    (\"Idaho\", \"ID\"),\n",
    "    (\"Illinois\", \"IL\"),\n",
    "    (\"Indiana\", \"IN\"),\n",
    "    (\"Iowa\", \"IA\"),\n",
    "    (\"Kansas\", \"KS\"),\n",
    "    (\"Kentucky\", \"KY\"),\n",
    "    (\"Louisiana\", \"LA\"),\n",
    "    (\"Maine\", \"ME\"),\n",
    "    (\"Maryland\", \"MD\"),\n",
    "    (\"Massachusetts\", \"MA\"),\n",
    "    (\"Michigan\", \"MI\"),\n",
    "    (\"Minnesota\", \"MN\"),\n",
    "    (\"Mississippi\", \"MS\"),\n",
    "    (\"Missouri\", \"MO\"),\n",
    "    (\"Montana\", \"MT\"),\n",
    "    (\"Nebraska\", \"NE\"),\n",
    "    (\"New Hampshire\", \"NH\"),\n",
    "    (\"New Mexico\", \"NM\"),\n",
    "    (\"New York\", \"NY\"),\n",
    "    (\"North Carolina\", \"NC\"),\n",
    "    (\"North Dakota\", \"ND\"),\n",
    "    (\"Ohio\", \"OH\"),\n",
    "    (\"Oklahoma\", \"OK\"),\n",
    "    (\"Pennsylvania\", \"PA\"),\n",
    "    (\"Rhode Island\", \"RI\"),\n",
    "    (\"South Carolina\", \"SC\"),\n",
    "    (\"South Dakota\", \"SD\"),\n",
    "    (\"Tennessee\", \"TN\"),\n",
    "    (\"Texas\", \"TX\"),\n",
    "    (\"Utah\", \"UT\"),\n",
    "    (\"Vermont\", \"VT\"),\n",
    "    (\"Virginia\", \"VA\"),\n",
    "    (\"Washington\", \"WA\"),\n",
    "    (\"West Virginia\", \"WV\"),\n",
    "    (\"Wisconsin\", \"WI\"),\n",
    "    (\"Wyoming\", \"WY\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_per_state = 10_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_df(df: pl.DataFrame, state_abv: str, samples: int = address_per_state) -> pl.DataFrame:\n",
    "    state_df = df.filter(pl.col('State') == state_abv)\n",
    "\n",
    "    sample_with_replacement = True if len(state_df) < samples else False\n",
    "\n",
    "    return state_df.sample(n=samples, seed=0, with_replacement=sample_with_replacement, shuffle=True) \n",
    "\n",
    "def build_dataset(df: pl.DataFrame, states: List[Tuple[str, str]]) -> pl.DataFrame:\n",
    "    dfs = [get_state_df(df, state_abv) for state, state_abv in states]\n",
    "    return pl.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = build_dataset(df, state_name_abbr_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 470000\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of samples: {len(sampled_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique states: 47\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of unique states: {len(sampled_df[\"State\"].unique())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df.write_parquet(project_dir / 'nad_sample_address.parquet', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence to Sequence Dataset prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = Path(os.getcwd()).parent\n",
    "data_dir = project_dir / 'Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (470000, 64)\n",
      "States: ['AK', 'MS', 'SD', 'TX', 'PA', 'AZ', 'NC', 'AL', 'KY', 'GA', 'LA', 'MA', 'MT', 'ID', 'SC', 'OK', 'RI', 'CO', 'FL', 'VT', 'IL', 'MO', 'WV', 'NM', 'DC', 'IN', 'NY', 'NE', 'OH', 'MI', 'DE', 'CT', 'CA', 'WI', 'NH', 'MD', 'UT', 'IA', 'ME', 'KS', 'TN', 'AR', 'VA', 'WY', 'ND', 'WA', 'MN']\n"
     ]
    }
   ],
   "source": [
    "df = pl.read_parquet(data_dir / 'address_dataset.parquet')\n",
    "print(f'Shape of data: {df.shape}')\n",
    "print(f\"States: {df['State'].unique().to_list()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 100\n"
     ]
    }
   ],
   "source": [
    "ma_df = df.filter(\n",
    "    pl.col('State') == 'MA'\n",
    ").sample(n=100, shuffle=True, with_replacement=False)\n",
    "\n",
    "print(f'Number of samples: {len(ma_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_clean_address(row: Dict) -> str:\n",
    "    \"\"\"Construct address from structured fields with type consistency\"\"\"\n",
    "    parts = []\n",
    "    \n",
    "    # Street component\n",
    "    street = []\n",
    "    if row.get('Add_Number') is not None:\n",
    "        street.append(str(int(row['Add_Number'])))\n",
    "    if row.get('St_Name'):\n",
    "        street.append(str(row['St_Name']).lower())\n",
    "    if street:\n",
    "        parts.append(' '.join(street))\n",
    "    \n",
    "    # Location component\n",
    "    location = []\n",
    "    if row.get('Post_City'):\n",
    "        location.append(str(row['Post_City']).lower())\n",
    "    if row.get('State'):\n",
    "        location.append(str(row['State']).lower())\n",
    "    if row.get('Zip_Code') is not None:\n",
    "        location.append(f\"{int(row['Zip_Code']):05d}\"[:5])\n",
    "    if location:\n",
    "        parts.append(', '.join(location))\n",
    "    \n",
    "    return ', '.join(parts)\n",
    "\n",
    "def add_character_noise(component: str) -> str:\n",
    "    \"\"\"Add character noise while maintaining string type\"\"\"\n",
    "    return ''.join([\n",
    "        random.choice(string.ascii_lowercase) \n",
    "        if c.isalpha() and random.random() < 0.2 \n",
    "        else c\n",
    "        for c in component\n",
    "    ]) if component else component\n",
    "\n",
    "def generate_noisy_address(row: Dict) -> str:\n",
    "    \"\"\"Generate noisy address with type-safe modifications\"\"\"\n",
    "    modified = row.copy()\n",
    "    \n",
    "    # 50% chance to remove street number (set to None)\n",
    "    if random.random() < 0.5:\n",
    "        modified['Add_Number'] = None\n",
    "    \n",
    "    # Add noise to street name (keep as string)\n",
    "    if modified.get('St_Name'):\n",
    "        modified['St_Name'] = add_character_noise(str(modified['St_Name']))\n",
    "    \n",
    "    # 30% chance to remove city (set to None)\n",
    "    if random.random() < 0.3:\n",
    "        modified['Post_City'] = None\n",
    "    \n",
    "    # 20% chance to modify zip code (keep as integer)\n",
    "    if modified.get('Zip_Code') and random.random() < 0.2:\n",
    "        zip_code = int(modified['Zip_Code'])\n",
    "        if 10000 <= zip_code <= 99999:\n",
    "            modified['Zip_Code'] = zip_code // 10  # Truncate last digit\n",
    "    \n",
    "    return build_clean_address(modified)\n",
    "\n",
    "def create_address_pairs(df: pl.DataFrame, n_noisy_varient_per_add: int = 3) -> pl.DataFrame:\n",
    "    \"\"\"Generate address pairs with schema consistency\"\"\"\n",
    "    results = []\n",
    "\n",
    "    for row in df.to_dicts():\n",
    "        oid = row['OID_']\n",
    "        state = row['State']\n",
    "\n",
    "        # Original clean target\n",
    "        clean_target = build_clean_address(row)\n",
    "        \n",
    "        # Add clean pair\n",
    "        results.append({\n",
    "            'oid': oid,\n",
    "            'source': clean_target,\n",
    "            'target': clean_target,\n",
    "            'state': state\n",
    "        })\n",
    "        \n",
    "        # Generate n noisy variants\n",
    "        for _ in range(n_noisy_varient_per_add):\n",
    "            noisy_source = generate_noisy_address(row)\n",
    "            results.append({\n",
    "                'oid': oid,\n",
    "                'source': noisy_source,\n",
    "                'target': clean_target,\n",
    "                'state': state\n",
    "            })\n",
    "    # Ensure schema consistency\n",
    "    return pl.DataFrame(results).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_pairs = create_address_pairs(ma_df, n_noisy_varient_per_add=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (369, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>oid</th><th>source</th><th>target</th><th>state</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>21805693</td><td>&quot;147 bafvzs, ma, 01776&quot;</td><td>&quot;147 haynes, ma, 01776&quot;</td><td>&quot;MA&quot;</td></tr><tr><td>21805693</td><td>&quot;147 haynes, ma, 01776&quot;</td><td>&quot;147 haynes, ma, 01776&quot;</td><td>&quot;MA&quot;</td></tr><tr><td>21805693</td><td>&quot;haynes, ma, 01776&quot;</td><td>&quot;147 haynes, ma, 01776&quot;</td><td>&quot;MA&quot;</td></tr><tr><td>21914186</td><td>&quot;95 squantum, ma, 02171&quot;</td><td>&quot;95 squantum, ma, 02171&quot;</td><td>&quot;MA&quot;</td></tr><tr><td>21914186</td><td>&quot;95 sqrantum, ma, 02171&quot;</td><td>&quot;95 squantum, ma, 02171&quot;</td><td>&quot;MA&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>25320323</td><td>&quot;35 timberlane, ma, 02649&quot;</td><td>&quot;35 timberlane, ma, 02649&quot;</td><td>&quot;MA&quot;</td></tr><tr><td>25320323</td><td>&quot;35 twmbeutane, ma, 02649&quot;</td><td>&quot;35 timberlane, ma, 02649&quot;</td><td>&quot;MA&quot;</td></tr><tr><td>25336079</td><td>&quot;188 ryver, ma, 01011&quot;</td><td>&quot;188 river, ma, 01011&quot;</td><td>&quot;MA&quot;</td></tr><tr><td>25336079</td><td>&quot;188 river, ma, 01011&quot;</td><td>&quot;188 river, ma, 01011&quot;</td><td>&quot;MA&quot;</td></tr><tr><td>25336079</td><td>&quot;188 rpver, ma, 01011&quot;</td><td>&quot;188 river, ma, 01011&quot;</td><td>&quot;MA&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (369, 4)\n",
       "┌──────────┬──────────────────────────┬──────────────────────────┬───────┐\n",
       "│ oid      ┆ source                   ┆ target                   ┆ state │\n",
       "│ ---      ┆ ---                      ┆ ---                      ┆ ---   │\n",
       "│ i64      ┆ str                      ┆ str                      ┆ str   │\n",
       "╞══════════╪══════════════════════════╪══════════════════════════╪═══════╡\n",
       "│ 21805693 ┆ 147 bafvzs, ma, 01776    ┆ 147 haynes, ma, 01776    ┆ MA    │\n",
       "│ 21805693 ┆ 147 haynes, ma, 01776    ┆ 147 haynes, ma, 01776    ┆ MA    │\n",
       "│ 21805693 ┆ haynes, ma, 01776        ┆ 147 haynes, ma, 01776    ┆ MA    │\n",
       "│ 21914186 ┆ 95 squantum, ma, 02171   ┆ 95 squantum, ma, 02171   ┆ MA    │\n",
       "│ 21914186 ┆ 95 sqrantum, ma, 02171   ┆ 95 squantum, ma, 02171   ┆ MA    │\n",
       "│ …        ┆ …                        ┆ …                        ┆ …     │\n",
       "│ 25320323 ┆ 35 timberlane, ma, 02649 ┆ 35 timberlane, ma, 02649 ┆ MA    │\n",
       "│ 25320323 ┆ 35 twmbeutane, ma, 02649 ┆ 35 timberlane, ma, 02649 ┆ MA    │\n",
       "│ 25336079 ┆ 188 ryver, ma, 01011     ┆ 188 river, ma, 01011     ┆ MA    │\n",
       "│ 25336079 ┆ 188 river, ma, 01011     ┆ 188 river, ma, 01011     ┆ MA    │\n",
       "│ 25336079 ┆ 188 rpver, ma, 01011     ┆ 188 river, ma, 01011     ┆ MA    │\n",
       "└──────────┴──────────────────────────┴──────────────────────────┴───────┘"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma_pairs.sort('oid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

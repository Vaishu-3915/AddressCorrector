{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45491,
     "status": "ok",
     "timestamp": 1745540591196,
     "user": {
      "displayName": "VENKAT",
      "userId": "12590802506526881118"
     },
     "user_tz": 240
    },
    "id": "IOYT6MMOJuH3",
    "outputId": "2d224044-56cc-4cd6-d6f5-4769819343af"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-d8746a8ca478>:7: UserWarning: WARNING: Unsloth should be imported before transformers, peft to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n",
      "\n",
      "Please restructure your imports with 'import unsloth' at the top of your file.\n",
      "  from unsloth import FastLanguageModel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "Unsloth: Failed to patch Gemma3ForConditionalGeneration.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "Unsloth: We'll be using `/tmp/unsloth_compiled_cache` for temporary Unsloth patches.\n",
      "Standard import failed for UnslothBCOTrainer: No module named 'UnslothBCOTrainer'. Using tempfile instead!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pinecone import Pinecone\n",
    "import torch\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from unsloth import FastLanguageModel\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PINECONE_API_KEY'] = \"add-api-key\"\n",
    "os.environ['PINECONE_ENVIRONMENT'] = \"us-east-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53,
     "status": "ok",
     "timestamp": 1745540594916,
     "user": {
      "displayName": "VENKAT",
      "userId": "12590802506526881118"
     },
     "user_tz": 240
    },
    "id": "dLqHS5RDJuKb",
    "outputId": "186632ed-665c-4ce8-f875-6a265ef6e8f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available. Using CUDA.\n"
     ]
    }
   ],
   "source": [
    "# Configuration for Retreiever and generator models\n",
    "\n",
    "# Retriever Model Configuration\n",
    "\n",
    "FINETUNED_RETRIEVER_PATH = 'output/finetuned-all-distilroberta-v1-2025-04-22_15-26-27'\n",
    "\n",
    "# Generator Model Configuration\n",
    "FINETUNED_GENERATOR_PATH =  \"llama3_sft_sfttrainer_MA/checkpoint-2500\"\n",
    "MAX_SEQ_LENGTH = 2048\n",
    "LOAD_IN_4BIT = True\n",
    "\n",
    "# Pinecone Configuration\n",
    "PINECONE_API_KEY = os.environ.get(\"PINECONE_API_KEY\", \"YOUR_API_KEY\")\n",
    "PINECONE_INDEX_NAME = 'address-data-index'\n",
    "\n",
    "# Retrieval Configuration - Number of relevant addresses to retrieve\n",
    "TOP_K_RETRIEVED = 5\n",
    "\n",
    "# --- Check GPU ---\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available. Using CUDA.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2664,
     "status": "ok",
     "timestamp": 1745540601514,
     "user": {
      "displayName": "VENKAT",
      "userId": "12590802506526881118"
     },
     "user_tz": 240
    },
    "id": "Jse416xHJuNa",
    "outputId": "8b4bed44-67df-43f8-9371-36ae83be504d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing Pinecone connection...\n",
      "Connected to Pinecone index 'address-data-index'.\n",
      "{'dimension': 768,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'': {'vector_count': 10000}},\n",
      " 'total_vector_count': 10000,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "# Initializing Pinecone connection\n",
    "\n",
    "print(\"\\nInitializing Pinecone connection...\")\n",
    "\n",
    "pinecone = Pinecone(api_key=PINECONE_API_KEY)\n",
    "if PINECONE_INDEX_NAME not in pinecone.list_indexes().names():\n",
    "      print(f\"Error: Index '{PINECONE_INDEX_NAME}' does not exist in Pinecone.\")\n",
    "index = pinecone.Index(PINECONE_INDEX_NAME)\n",
    "print(f\"Connected to Pinecone index '{PINECONE_INDEX_NAME}'.\")\n",
    "print(index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30371,
     "status": "ok",
     "timestamp": 1745540635776,
     "user": {
      "displayName": "VENKAT",
      "userId": "12590802506526881118"
     },
     "user_tz": 240
    },
    "id": "HrinTg6JJuTN",
    "outputId": "e98bbc30-695b-4061-af30-db352c90dc5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever model loaded successfully to cuda:0.\n"
     ]
    }
   ],
   "source": [
    "# Loading fine-tuned retriever model\n",
    "\n",
    "retriever_model = SentenceTransformer(FINETUNED_RETRIEVER_PATH, device=str(device))\n",
    "print(f\"Retriever model loaded successfully to {retriever_model.device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220,
     "referenced_widgets": [
      "cd1bc130b1e047569c5725744090af02",
      "0be31f639d5d495d97dd8cef9609e277",
      "86b4957600384ad7b2816ef2a1133fe7",
      "75b39611d07d4c79910a24827668d848",
      "5c0704de17aa47d5836e187eff8e8000",
      "a0a3a84bbfe1459ea98e502b1db572f4",
      "d913b45a8b5f48e783e88a781ffd540f",
      "8a31a2e4a52d408790e298a4338cdb2a",
      "18ab15a97d3e42a8aa06312de4de9824",
      "71a722b4755d41f2bd1cb97afca22876",
      "e1c25dc9ab9c4b0498a2874d7ce11b5e",
      "8d41d30d4e2a4900a758e25dd7b172b5",
      "bf62a2e5e7ef4c0080a1b0f5c330feb0",
      "62b045e5d2714bf3aaa1d076b55d5e41",
      "54753c3e6b5d4b11b1587bddb205cd05",
      "bd21bec302034ebd9ee4ae880f15f7a8",
      "5f7a849e19e94562a045520458eadd5d",
      "1209a63d2eb94caca96dd43ac49a4733",
      "08798421b93040a0a2547f98bc3805fc",
      "e9570cd72978408c9bb6194468d4ced7",
      "ab0fbaca5e634668989f27b4384fca3b",
      "6f4772999dc340b6b15240af0e9a58b7"
     ]
    },
    "executionInfo": {
     "elapsed": 32747,
     "status": "ok",
     "timestamp": 1745540885143,
     "user": {
      "displayName": "VENKAT",
      "userId": "12590802506526881118"
     },
     "user_tz": 240
    },
    "id": "VWOlVF4VJuV6",
    "outputId": "d768b47c-653b-4db3-bda6-c56b17ccdcf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd1bc130b1e047569c5725744090af02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.03G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d41d30d4e2a4900a758e25dd7b172b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.3.19 patched 16 layers with 16 QKV layers, 16 O layers and 16 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator LLM loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load Generator LLM (Unsloth Llama 3.2)\n",
    "\n",
    "generator_model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = FINETUNED_GENERATOR_PATH,\n",
    "    max_seq_length = MAX_SEQ_LENGTH,\n",
    "    dtype = None,\n",
    "    load_in_4bit = LOAD_IN_4BIT,\n",
    ")\n",
    "print(\"Generator LLM loaded successfully.\")\n",
    "\n",
    "# Set pad token if missing (common for Llama models)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1745540888916,
     "user": {
      "displayName": "VENKAT",
      "userId": "12590802506526881118"
     },
     "user_tz": 240
    },
    "id": "dE3Y3IaPLrHe",
    "outputId": "63478cf1-9550-4e4f-dcef-fafe90f355f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth inference optimizations enabled.\n"
     ]
    }
   ],
   "source": [
    "# Enable Unsloth inference optimizations\n",
    "FastLanguageModel.for_inference(generator_model)\n",
    "print(\"Unsloth inference optimizations enabled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1745540894746,
     "user": {
      "displayName": "VENKAT",
      "userId": "12590802506526881118"
     },
     "user_tz": 240
    },
    "id": "PNGN0gMCLrKZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define Retrieval Function\n",
    "\n",
    "def get_relevant_addresses(query_address: str, top_k: int = TOP_K_RETRIEVED) -> list:\n",
    "    # Generate embedding for the query address\n",
    "    query_embedding = retriever_model.encode(\n",
    "        query_address,\n",
    "        convert_to_tensor=False,\n",
    "        device=str(device)\n",
    "    ).tolist()\n",
    "\n",
    "    # Query Pinecone\n",
    "    query_response = index.query(\n",
    "        vector=query_embedding,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True\n",
    "    )\n",
    "\n",
    "    # Extract address text from metadata\n",
    "    context_addresses = []\n",
    "    if query_response.matches:\n",
    "        for match in query_response.matches:\n",
    "            if match.metadata and 'address_text' in match.metadata:\n",
    "                context_addresses.append(match.metadata['address_text'])\n",
    "            print(f\"  - Retrieved ID: {match.id}, Score: {match.score:.4f}\")\n",
    "\n",
    "    print(f\"Retrieved {len(context_addresses)} context addresses.\")\n",
    "    print(context_addresses)\n",
    "    return context_addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1745541912244,
     "user": {
      "displayName": "VENKAT",
      "userId": "12590802506526881118"
     },
     "user_tz": 240
    },
    "id": "JY70Ib_BLrN1"
   },
   "outputs": [],
   "source": [
    "# Define Prediction Function\n",
    "\n",
    "llama3_2_instruct_template = \"\"\"\n",
    "\n",
    "You are an address rewriting bot, please rewrite the following address according to standard address hierarchy and\n",
    "related addresses to onea single correct address. Related addresses are possibly geographically close to the address to be rewritten.\n",
    "If no rewrite is needed, output the original address.\n",
    "\n",
    "Address to be rewritten: {query_address}\n",
    "\n",
    "Address Hierarchy: [Number, Street, City, State, ZIP]\n",
    "\n",
    "Examples: 6, Jade Street, Methuen, Essex County, Massachusetts, 01844\n",
    "\n",
    "Related Address: {context_list}\n",
    "\n",
    "The generated result should be one line containing only one corrected address as below\n",
    "#Corrected Address: (generated address) #\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def predict_address(query_address: str, context_addresses: list) -> str:\n",
    "    print(\"Constructing prompt and generating prediction...\")\n",
    "\n",
    "    if context_addresses:\n",
    "        context_str = \"\\n\".join([f\"- {addr}\" for addr in context_addresses])\n",
    "    else:\n",
    "        context_str = \"None provided.\"\n",
    "\n",
    "    # Create the prompt using the template\n",
    "    prompt = llama3_2_instruct_template.format(\n",
    "        query_address=query_address,\n",
    "        context_list=context_str\n",
    "    )\n",
    "    print(f'Prompt:{prompt}')\n",
    "    # Prepare input for the generator model\n",
    "    inputs = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(device)\n",
    "\n",
    "    # Generation parameters (adjust as needed)\n",
    "    generation_params = {\n",
    "        \"max_new_tokens\": 1000,\n",
    "        \"do_sample\": False,\n",
    "        \"pad_token_id\": tokenizer.eos_token_id\n",
    "    }\n",
    "\n",
    "    # Generate the output\n",
    "    try:\n",
    "        print(\"Generating response...\")\n",
    "        outputs = generator_model.generate(**inputs, **generation_params)\n",
    "        generated_ids = outputs[0, inputs['input_ids'].shape[1]:]\n",
    "        result = tokenizer.decode(generated_ids, skip_special_tokens=True).strip()\n",
    "        print(\"Generation complete.\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error during generation: {e}\")\n",
    "        return f\"Error: Could not generate prediction ({e})\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34728,
     "status": "ok",
     "timestamp": 1745542166406,
     "user": {
      "displayName": "VENKAT",
      "userId": "12590802506526881118"
     },
     "user_tz": 240
    },
    "id": "t-_1HwyGLrRV",
    "outputId": "8035c7b4-4693-49cf-f072-804f3871b21a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running RAG for Query: '32, Clarkwood Street testing, Unit 3 KUHIUHBK, Mattapan, 02126' ---\n",
      "  - Retrieved ID: 24428299, Score: 0.9584\n",
      "  - Retrieved ID: 24563225, Score: 0.9577\n",
      "  - Retrieved ID: 24464669, Score: 0.9572\n",
      "  - Retrieved ID: 24548964, Score: 0.9571\n",
      "  - Retrieved ID: 24429973, Score: 0.9567\n",
      "Retrieved 5 context addresses.\n",
      "['1000, Harvard Street, Unit 12, Mattapan, Suffolk County, Massachusetts, 02126', '40, Fairlawn Avenue, Unit c7, Mattapan, Suffolk County, Massachusetts, 02126', '219, Delhi Street, Unit 11, Mattapan, Suffolk County, Massachusetts, 02126', '49, Woolson Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126', '32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126']\n",
      "Constructing prompt and generating prediction...\n",
      "Prompt:\n",
      "\n",
      "You are an address rewriting bot, please rewrite the following address according to standard address hierarchy and\n",
      "related addresses to onea single correct address. Related addresses are possibly geographically close to the address to be rewritten.\n",
      "If no rewrite is needed, output the original address. \n",
      "\n",
      "Address to be rewritten: 32, Clarkwood Street testing, Unit 3 KUHIUHBK, Mattapan, 02126\n",
      "\n",
      "Address Hierarchy: [Number, Street, City, State, ZIP]\n",
      "\n",
      "Examples: 6, Jade Street, Methuen, Essex County, Massachusetts, 01844\n",
      "\n",
      "Related Address: - 1000, Harvard Street, Unit 12, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 40, Fairlawn Avenue, Unit c7, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 219, Delhi Street, Unit 11, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 49, Woolson Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "\n",
      "The generated result should be one line containing only one corrected address as below\n",
      "#Corrected Address: (generated address) #\n",
      "\n",
      "\n",
      "Generating response...\n",
      "Generation complete.\n",
      "Predicted/Rewritten Address: Corrected Address: 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "\n",
      "Output:\n",
      "32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Mattapan, Suffolk County, Massachusetts, 02126\n",
      "- 32, Clarkwood Street, Unit 3, Matt\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #query address \n",
    "    query = \"32, Clarkwood Street testing, Unit 3 KUHIUHBK, Mattapan, 02126\"\n",
    "\n",
    "    print(f\"\\n--- Running RAG for Query: '{query}' ---\")\n",
    "\n",
    "    # 1. Retrieve context\n",
    "    context = get_relevant_addresses(query)\n",
    "\n",
    "    # 2. Generate prediction using context\n",
    "    predicted_address = predict_address(query, context)\n",
    "    print(\"\\n--- Prediction Result ---\")\n",
    "    print(f\"Original Query: {query}\")\n",
    "    print(f\"Predicted/Rewritten Address: {predicted_address}\")\n",
    "    print(\"-------------------------\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPk/M/uZOBKeRROC4np4pmi",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

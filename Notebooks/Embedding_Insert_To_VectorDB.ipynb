{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 23861,
     "status": "ok",
     "timestamp": 1745336152920,
     "user": {
      "displayName": "VENKAT",
      "userId": "12590802506526881118"
     },
     "user_tz": 240
    },
    "id": "nS6jypGdDtQP"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pinecone import Pinecone, ServerlessSpec, PodSpec\n",
    "import torch\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 799,
     "status": "ok",
     "timestamp": 1745336191886,
     "user": {
      "displayName": "VENKAT",
      "userId": "12590802506526881118"
     },
     "user_tz": 240
    },
    "id": "qehKmv-DDtWJ"
   },
   "outputs": [],
   "source": [
    "os.environ['PINECONE_API_KEY'] = \"add-api-key\"\n",
    "os.environ['PINECONE_ENVIRONMENT'] = \"us-east-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 118,
     "status": "ok",
     "timestamp": 1745336204041,
     "user": {
      "displayName": "VENKAT",
      "userId": "12590802506526881118"
     },
     "user_tz": 240
    },
    "id": "4T9zj6EzDtY0",
    "outputId": "f4bdd5b3-e002-4b47-c935-efd4f63108cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available. Using CUDA.\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "\n",
    "FINETUNED_MODEL_PATH = 'output/finetuned-all-distilroberta-v1-2025-04-22_15-26-27'\n",
    "INPUT_PARQUET_PATH = 'new_formatted_addresses.parquet'\n",
    "ID_COLUMN = 'OID_'\n",
    "ADDRESS_COLUMN = 'FormattedFullAddress'\n",
    "LAT_COLUMN = 'Latitude'\n",
    "LON_COLUMN = 'Longitude'\n",
    "\n",
    "# Pinecone Configuration\n",
    "PINECONE_API_KEY = os.environ.get(\"PINECONE_API_KEY\")\n",
    "PINECONE_ENVIRONMENT = os.environ.get(\"PINECONE_ENVIRONMENT\")\n",
    "PINECONE_INDEX_NAME = 'address-data-index'\n",
    "MODEL_EMBEDDING_DIMENSION = 768\n",
    "PINECONE_METRIC = 'cosine'\n",
    "PINECONE_SPEC = ServerlessSpec(cloud='aws', region='us-east-1')\n",
    "\n",
    "# Processing Configuration\n",
    "UPSERT_BATCH_SIZE = 100\n",
    "ENCODE_BATCH_SIZE = 64\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available. Using CUDA.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10450,
     "status": "ok",
     "timestamp": 1745336218215,
     "user": {
      "displayName": "VENKAT",
      "userId": "12590802506526881118"
     },
     "user_tz": 240
    },
    "id": "NvNj6ztoD4ZU",
    "outputId": "40171794-a914-45bb-f862-9610f0266e01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing Pinecone connection...\n",
      "Index 'address-data-index' does not exist. Creating...\n",
      "Created new index: address-data-index\n",
      "Connected to Pinecone index.\n",
      "{'dimension': 768,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {},\n",
      " 'total_vector_count': 0,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize Pinecone\n",
    "\n",
    "print(\"\\nInitializing Pinecone connection...\")\n",
    "\n",
    "pinecone = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Check if index exists\n",
    "if PINECONE_INDEX_NAME not in pinecone.list_indexes().names():\n",
    "    print(f\"Index '{PINECONE_INDEX_NAME}' does not exist. Creating...\")\n",
    "    pinecone.create_index(\n",
    "        name=PINECONE_INDEX_NAME,\n",
    "        dimension=MODEL_EMBEDDING_DIMENSION,\n",
    "        metric=PINECONE_METRIC,\n",
    "        spec=PINECONE_SPEC\n",
    "    )\n",
    "    print(f\"Created new index: {PINECONE_INDEX_NAME}\")\n",
    "else:\n",
    "    print(f\"Index '{PINECONE_INDEX_NAME}' already exists.\")\n",
    "\n",
    "# Connect to the index\n",
    "index = pinecone.Index(PINECONE_INDEX_NAME)\n",
    "print(\"Connected to Pinecone index.\")\n",
    "print(index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29429,
     "status": "ok",
     "timestamp": 1745336267205,
     "user": {
      "displayName": "VENKAT",
      "userId": "12590802506526881118"
     },
     "user_tz": 240
    },
    "id": "Egfa2QjZD4cq",
    "outputId": "a06c1c40-9a48-4769-abc9-657d0c2aba2d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned model loaded successfully to cuda:0.\n"
     ]
    }
   ],
   "source": [
    "# Loading Fine-tuned Model\n",
    "\n",
    "model = SentenceTransformer(FINETUNED_MODEL_PATH, device=str(device))\n",
    "test_embedding = model.encode(\"test\")\n",
    "print(f\"Fine-tuned model loaded successfully to {model.device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8944,
     "status": "ok",
     "timestamp": 1745336282867,
     "user": {
      "displayName": "VENKAT",
      "userId": "12590802506526881118"
     },
     "user_tz": 240
    },
    "id": "485deL7FD4fp",
    "outputId": "b8b802aa-ed1e-4382-bb25-d05efff81cf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 10000 rows initially.\n"
     ]
    }
   ],
   "source": [
    "# Load Address Data\n",
    "\n",
    "df_raw = pd.read_parquet(INPUT_PARQUET_PATH)\n",
    "df = df_raw[df_raw['State'].str.lower() == 'ma']\n",
    "print(f\"Successfully loaded {len(df)} rows initially.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240,
      "referenced_widgets": [
       "506eadd47bfd4559b7367d9b787ef301",
       "f6bf0510c2154c5ca1f5d0de56e83519",
       "e66a1b5c3efc42b5b7cf49e7daa83bdf",
       "f1d08df3112949d6aef70fd7d37385c7",
       "2511b5ce173b4887806aad4d7730c7c9",
       "b8d0df572b2c463bbdb9a2c81bd28705",
       "aa26e9a718de461bbb01ae7ff75dcfb5",
       "3a1fd632120e4b0ba5e448e13076d0c5",
       "a207d1459e604b5b82b4dabd9cf777bb",
       "8df52786cf364dee9baf96c7bca3c04b",
       "bf3fd9fdd36040908d5ae0b42fc07c54"
      ]
    },
    "executionInfo": {
     "elapsed": 100925,
     "status": "ok",
     "timestamp": 1745336400713,
     "user": {
      "displayName": "VENKAT",
      "userId": "12590802506526881118"
     },
     "user_tz": 240
    },
    "id": "UNpNeVwRD4iw",
    "outputId": "6429ff40-d50e-4ef3-f112-4a7ca36aa256"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting embedding generation and upsert process for 10000 records...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "506eadd47bfd4559b7367d9b787ef301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserting Batches:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Upsert Process Complete ---\n",
      "Final Pinecone index stats:\n",
      "{'dimension': 768,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'': {'vector_count': 10000}},\n",
      " 'total_vector_count': 10000,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "# Generate Embeddings and Upsert to Pinecone in Batches\n",
    "\n",
    "print(f\"\\nStarting embedding generation and upsert process for {len(df)} records...\")\n",
    "total_records = len(df)\n",
    "\n",
    "for i in tqdm(range(0, total_records, UPSERT_BATCH_SIZE), desc=\"Upserting Batches\"):\n",
    "    batch_df = df.iloc[i : i + UPSERT_BATCH_SIZE]\n",
    "\n",
    "    # Get address texts for the current batch\n",
    "    texts_to_encode = batch_df[ADDRESS_COLUMN].tolist()\n",
    "\n",
    "    # Generate embeddings for the batch\n",
    "\n",
    "    embeddings = model.encode(\n",
    "        texts_to_encode,\n",
    "        batch_size=ENCODE_BATCH_SIZE,\n",
    "        show_progress_bar=False,\n",
    "        device=str(device)\n",
    "      )\n",
    "\n",
    "    # Prepare vectors for Pinecone upsert\n",
    "    vectors_to_upsert = []\n",
    "    for row_idx, (df_index, row) in enumerate(batch_df.iterrows()):\n",
    "        embedding = embeddings[row_idx].tolist()\n",
    "        vector_id = str(row[ID_COLUMN])\n",
    "\n",
    "        # Create metadata dictionary\n",
    "        metadata = {\"address_text\": str(row[ADDRESS_COLUMN])}\n",
    "        if LAT_COLUMN in row and pd.notna(row[LAT_COLUMN]):\n",
    "             metadata[\"latitude\"] = float(row[LAT_COLUMN])\n",
    "        if LON_COLUMN in row and pd.notna(row[LON_COLUMN]):\n",
    "             metadata[\"longitude\"] = float(row[LON_COLUMN])\n",
    "\n",
    "        vectors_to_upsert.append({\n",
    "            \"id\": vector_id,\n",
    "            \"values\": embedding,\n",
    "            \"metadata\": metadata\n",
    "        })\n",
    "\n",
    "    # Upsert the batch to Pinecone\n",
    "    index.upsert(vectors=vectors_to_upsert)\n",
    "\n",
    "\n",
    "print(\"\\n--- Upsert Process Complete ---\")\n",
    "\n",
    "final_stats = index.describe_index_stats()\n",
    "print(\"Final Pinecone index stats:\")\n",
    "print(final_stats)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOsT9s50ErkeNnZj9tqGEFP",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

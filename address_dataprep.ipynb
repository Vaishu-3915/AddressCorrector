{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.12\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install polars==1.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polars version: 1.9.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "print(f'polars version: {pl.__version__}')\n",
    "\n",
    "project_dir = Path(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://nationaladdressdata.s3.amazonaws.com/NAD_r18_TXT.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip_data_file_path = project_dir / 'NAD_r18_TXT.zip'\n",
    "\n",
    "# with zipfile.ZipFile(zip_data_file_path, 'r') as zip_ref:\n",
    "#     zip_ref.extractall(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_file_path = project_dir / 'TXT/NAD_r18.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polars                        1.26.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_overrides = {\n",
    "    \"OID_\": pl.Int64,\n",
    "    \"AddNum_Pre\": pl.Utf8,\n",
    "    \"Add_Number\": pl.Int64,\n",
    "    \"AddNum_Suf\": pl.Utf8,\n",
    "    \"AddNo_Full\": pl.Int64,\n",
    "    \"St_PreMod\": pl.Utf8,\n",
    "    \"St_PreDir\": pl.Utf8,\n",
    "    \"St_PreTyp\": pl.Utf8,\n",
    "    \"St_PreSep\": pl.Utf8,\n",
    "    \"St_Name\": pl.Utf8,\n",
    "    \"St_PosTyp\": pl.Utf8,\n",
    "    \"St_PosDir\": pl.Utf8,\n",
    "    \"St_PosMod\": pl.Utf8,\n",
    "    \"StNam_Full\": pl.Utf8,\n",
    "    \"Building\": pl.Utf8,\n",
    "    \"Floor\": pl.Utf8,\n",
    "    \"Unit\": pl.Utf8,\n",
    "    \"Room\": pl.Utf8,\n",
    "    \"Seat\": pl.Utf8,\n",
    "    \"Addtl_Loc\": pl.Utf8,\n",
    "    \"SubAddress\": pl.Utf8,\n",
    "    \"LandmkName\": pl.Utf8,\n",
    "    \"County\": pl.Utf8,\n",
    "    \"Inc_Muni\": pl.Utf8,\n",
    "    \"Post_City\": pl.Utf8,\n",
    "    \"Census_Plc\": pl.Utf8,\n",
    "    \"Uninc_Comm\": pl.Utf8,\n",
    "    \"Nbrhd_Comm\": pl.Utf8,\n",
    "    \"NatAmArea\": pl.Utf8,\n",
    "    \"NatAmSub\": pl.Utf8,\n",
    "    \"Urbnztn_PR\": pl.Utf8,\n",
    "    \"PlaceOther\": pl.Utf8,\n",
    "    \"PlaceNmTyp\": pl.Utf8,\n",
    "    \"State\": pl.Utf8,\n",
    "    \"Zip_Code\": pl.Int64,\n",
    "    \"Plus_4\": pl.Int64,\n",
    "    \"UUID\": pl.Utf8,\n",
    "    \"AddAuth\": pl.Int64,\n",
    "    \"AddrRefSys\": pl.Utf8,\n",
    "    \"Longitude\": pl.Float64,\n",
    "    \"Latitude\": pl.Float64,\n",
    "    \"NatGrid\": pl.Utf8,\n",
    "    \"Elevation\": pl.Utf8,\n",
    "    \"Placement\": pl.Utf8,\n",
    "    \"AddrPoint\": pl.Utf8,\n",
    "    \"Related_ID\": pl.Utf8,\n",
    "    \"RelateType\": pl.Utf8,\n",
    "    \"ParcelSrc\": pl.Utf8,\n",
    "    \"Parcel_ID\": pl.Utf8,\n",
    "    \"AddrClass\": pl.Utf8,\n",
    "    \"Lifecycle\": pl.Utf8,\n",
    "    \"Effective\": pl.Utf8,\n",
    "    \"Expire\": pl.Utf8,\n",
    "    \"DateUpdate\": pl.Utf8,\n",
    "    \"AnomStatus\": pl.Utf8,\n",
    "    \"LocatnDesc\": pl.Utf8,\n",
    "    \"Addr_Type\": pl.Utf8,\n",
    "    \"DeliverTyp\": pl.Utf8,\n",
    "    \"NAD_Source\": pl.Utf8,\n",
    "    \"DataSet_ID\": pl.Utf8,\n",
    "    \"StreetAddress\": pl.Utf8,\n",
    "    \"SecondaryAddress\": pl.Utf8,\n",
    "    \"CityStateZip\": pl.Utf8,\n",
    "    \"FullAddress\": pl.Utf8,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv(\n",
    "    raw_file_path, \n",
    "    ignore_errors=True, \n",
    "    separator=\",\", \n",
    "    infer_schema_length=0, \n",
    "    quote_char=None, \n",
    "    schema_overrides=schema_overrides,\n",
    "    truncate_ragged_lines=True,\n",
    "    null_values=[\"Not stated\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(pl.col('State').is_not_null())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_states = [\n",
    "    'TX', 'LA', 'ME', 'WY', 'KY', 'MI', 'WA', 'VT', 'ND', 'TN',\n",
    "    'IN', 'WV', 'MN', 'RI', 'DE', 'IL', 'SD', 'AK', 'MS', 'OK',\n",
    "    'PA', 'WI', 'NY', 'KS', 'NM', 'AZ', 'SC', 'FL', 'NC', 'MD',\n",
    "    'UT', 'NE', 'NH', 'VA', 'GA', 'AL', 'CA', 'MA', 'CT', 'AR',\n",
    "    'CO', 'MT', 'DC', 'ID', 'IA', 'OH', 'MO'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(\n",
    "    pl.col('State').is_in(valid_states)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 80044721\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of records: {len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.with_columns(\n",
    "    pl.concat_str(\n",
    "        [\n",
    "            pl.col(\"AddNum_Pre\"),\n",
    "            pl.col(\"Add_Number\").cast(str),\n",
    "            pl.col(\"AddNum_Suf\"),\n",
    "            pl.col(\"St_PreMod\"),\n",
    "            pl.col(\"St_PreDir\"),\n",
    "            pl.col(\"St_PreTyp\"),\n",
    "            pl.col(\"St_Name\"),\n",
    "            pl.col(\"St_PosTyp\"),\n",
    "            pl.col(\"St_PosDir\"),\n",
    "            pl.col(\"St_PosMod\")\n",
    "        ],\n",
    "        separator=\" \",\n",
    "        ignore_nulls=True\n",
    "    ).alias(\"StreetAddress\"),\n",
    "    pl.concat_str(\n",
    "        [\n",
    "            pl.col(\"Building\"),\n",
    "            pl.col(\"Floor\"),\n",
    "            pl.col(\"Unit\"),\n",
    "            pl.col(\"Room\"),\n",
    "            pl.col(\"Seat\"),\n",
    "            pl.col(\"Addtl_Loc\"),\n",
    "            pl.col(\"SubAddress\")\n",
    "        ],\n",
    "        separator=\", \",\n",
    "        ignore_nulls=True\n",
    "    ).alias(\"SecondaryAddress\"),\n",
    "    pl.concat_str(\n",
    "        [\n",
    "            pl.col(\"Post_City\"),\n",
    "            pl.col(\"State\"),\n",
    "            pl.concat_str(\n",
    "                [pl.col(\"Zip_Code\").cast(str), pl.col(\"Plus_4\").cast(str)],\n",
    "                separator=\"-\",\n",
    "                ignore_nulls=True\n",
    "            )\n",
    "        ],\n",
    "        separator=\", \",\n",
    "        ignore_nulls=True\n",
    "    ).alias(\"CityStateZip\")\n",
    ")\n",
    "\n",
    "df = df.with_columns(\n",
    "    pl.concat_str(\n",
    "        [\n",
    "            pl.col(\"StreetAddress\"),\n",
    "            pl.col(\"SecondaryAddress\"),\n",
    "            pl.col(\"CityStateZip\")\n",
    "        ],\n",
    "        separator=\"\\n\",\n",
    "        ignore_nulls=True\n",
    "    ).alias(\"FullAddress\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Address Length: 42.41529813065374 | Median Address Length: 41.0\n"
     ]
    }
   ],
   "source": [
    "mean_add_len = df.with_columns(pl.col('FullAddress').str.len_chars().alias('AddressLength'))['AddressLength'].mean()\n",
    "median_add_len = df.with_columns(pl.col('FullAddress').str.len_chars().alias('AddressLength'))['AddressLength'].median()\n",
    "\n",
    "print(f'Mean Address Length: {mean_add_len} | Median Address Length: {median_add_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_name_abbr_tuples = [\n",
    "    (\"Alabama\", \"AL\"),\n",
    "    (\"Alaska\", \"AK\"),\n",
    "    (\"Arizona\", \"AZ\"),\n",
    "    (\"Arkansas\", \"AR\"),\n",
    "    (\"California\", \"CA\"),\n",
    "    (\"Colorado\", \"CO\"),\n",
    "    (\"Connecticut\", \"CT\"),\n",
    "    (\"Delaware\", \"DE\"),\n",
    "    (\"District of Columbia\", \"DC\"),\n",
    "    (\"Florida\", \"FL\"),\n",
    "    (\"Georgia\", \"GA\"),\n",
    "    (\"Idaho\", \"ID\"),\n",
    "    (\"Illinois\", \"IL\"),\n",
    "    (\"Indiana\", \"IN\"),\n",
    "    (\"Iowa\", \"IA\"),\n",
    "    (\"Kansas\", \"KS\"),\n",
    "    (\"Kentucky\", \"KY\"),\n",
    "    (\"Louisiana\", \"LA\"),\n",
    "    (\"Maine\", \"ME\"),\n",
    "    (\"Maryland\", \"MD\"),\n",
    "    (\"Massachusetts\", \"MA\"),\n",
    "    (\"Michigan\", \"MI\"),\n",
    "    (\"Minnesota\", \"MN\"),\n",
    "    (\"Mississippi\", \"MS\"),\n",
    "    (\"Missouri\", \"MO\"),\n",
    "    (\"Montana\", \"MT\"),\n",
    "    (\"Nebraska\", \"NE\"),\n",
    "    (\"New Hampshire\", \"NH\"),\n",
    "    (\"New Mexico\", \"NM\"),\n",
    "    (\"New York\", \"NY\"),\n",
    "    (\"North Carolina\", \"NC\"),\n",
    "    (\"North Dakota\", \"ND\"),\n",
    "    (\"Ohio\", \"OH\"),\n",
    "    (\"Oklahoma\", \"OK\"),\n",
    "    (\"Pennsylvania\", \"PA\"),\n",
    "    (\"Rhode Island\", \"RI\"),\n",
    "    (\"South Carolina\", \"SC\"),\n",
    "    (\"South Dakota\", \"SD\"),\n",
    "    (\"Tennessee\", \"TN\"),\n",
    "    (\"Texas\", \"TX\"),\n",
    "    (\"Utah\", \"UT\"),\n",
    "    (\"Vermont\", \"VT\"),\n",
    "    (\"Virginia\", \"VA\"),\n",
    "    (\"Washington\", \"WA\"),\n",
    "    (\"West Virginia\", \"WV\"),\n",
    "    (\"Wisconsin\", \"WI\"),\n",
    "    (\"Wyoming\", \"WY\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_per_state = 10_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_df(df: pl.DataFrame, state_abv: str, samples: int = address_per_state) -> pl.DataFrame:\n",
    "    state_df = df.filter(pl.col('State') == state_abv)\n",
    "\n",
    "    sample_with_replacement = True if len(state_df) < samples else False\n",
    "\n",
    "    return state_df.sample(n=samples, seed=0, with_replacement=sample_with_replacement, shuffle=True) \n",
    "\n",
    "def build_dataset(df: pl.DataFrame, states: List[Tuple[str, str]]) -> pl.DataFrame:\n",
    "    dfs = [get_state_df(df, state_abv) for state, state_abv in states]\n",
    "    return pl.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = build_dataset(df, state_name_abbr_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 470000\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of samples: {len(sampled_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique states: 47\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of unique states: {len(sampled_df[\"State\"].unique())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df.write_parquet(project_dir / 'nad_sample_address.parquet', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_parquet(project_dir.parent / 'Data/nad_sample_address.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (470000, 64)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of data: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
